{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.0 Automatically Generate Synthetic Dataset\n",
    "\n",
    "In this notebook, you'll explore the [Omniverse Replicator](https://docs.omniverse.nvidia.com/prod_extensions/prod_extensions/ext_replicator.html) API and create your own synthetic dataset with a script in \"headless\" mode.\n",
    "\n",
    "**[0.1 Learning Objectives](#0.1-Learning-Objectives)<br>**\n",
    "**[0.2 Omniverse Code GUI Demo](#0.-Omniverse-Code-GUI-Demo)<br>**\n",
    "**[0.3 Walk Through Our Replicator Script](#0.3-Walk-Through-Our-Replicator-Script)<br>**\n",
    "**[0.4 Running the Replicator Script](#0.4-Running-the-Replicator-Script)<br>**\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[0.4.1 Bonus Replicator API Work](#0.4.1-Bonus-Replicator-API-Work)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 0.1 Learning Objectives\n",
    "\n",
    "In this first notebook we will step through each piece of a Replicator script to create synthetic data. At the end of the notebook, you'll run the data generation script.  \n",
    "\n",
    "This notebook introduces:\n",
    "- **Omniverse Replicator API:** - Python API for generating physically accurate synthetic data. ([Replicator Core API documentation](https://docs.omniverse.nvidia.com/py/replicator/1.6.4/source/extensions/omni.replicator.core/docs/index.html))\n",
    "- **Omniverse Replicator Headless:** - Running Replicator scripts without using the Omniverse GUI. ([Running Replicator Headlessly documentation](https://docs.omniverse.nvidia.com/app_code/prod_extensions/ext_replicator/headless_example.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 0.2 Omniverse Code GUI Demo\n",
    "\n",
    "Before walking through the data generation script, watch this video to learn how this could be done in the Omniverse Code GUI. Omniverse is installed on the VM Desktop if you would like to experiment for yourself!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><video controls src=\"https://dli-lms.s3.amazonaws.com/assets/s-ov-10-v1/DLI_part_2.mp4\" width=800 ></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 0.3 Walk Through Our Replicator Script\n",
    "\n",
    "Now that you've seen how to run the script from the GUI, watch this quick intro video on running the script headlessly. \n",
    "\n",
    "Remember, you will only be running the script at the end of the notebook; the rest is a guided walkthrough of the Replicator API script we are using."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><video controls src=\"https://dli-lms.s3.amazonaws.com/assets/s-ov-10-v1/DLI_part_3.mp4\" width=800 ></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Python Replicator API, we will generate the RGB images and labeled bounding box data that we need to fine-tune a pretrained model later.\n",
    "\n",
    "We utilize the current `datetime` at the end of this Python script to add the current date to our output data folder. That way, if we end up generating multiple datasets we can easily tell them apart.\n",
    "\n",
    "The `omni.replicator.core` import is the Replicator API functionality that we are pulling from Omniverse. We will see lots of Replicator-specific syntax throughout this script. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "import omni.replicator.core as rep\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we do is create a new [universal scene description (USD) layer](https://docs.omniverse.nvidia.com/extensions/latest/ext_layers.html). A layer in this context is used to organize our scene. We are working with a single layer for this example.\n",
    "\n",
    "Next, we define the 3D objects that will make up our scene. The paths here correspond to the location of the USD in the shared Omniverse drive on the Code GUI as we saw in the original GUI demo.\n",
    "\n",
    "The `FRUIT_PROPS` outlines all the fruits we will be filling our crate with, you will see as we continue how we randomize the fruits to make each frame we generate unique. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "with rep.new_layer():\n",
    "    CRATE = 'omniverse://ove-nucleus.courses.nvidia.com/NVIDIA/Samples/Marbles/assets/standalone/SM_room_crate_3/SM_room_crate_3.usd'\n",
    "    SURFACE = 'omniverse://ove-nucleus.courses.nvidia.com/NVIDIA/Assets/Scenes/Templates/Basic/display_riser.usd'\n",
    "    ENVS = 'omniverse://ove-nucleus.courses.nvidia.com/NVIDIA/Assets/Scenes/Templates/Interior/ZetCG_ExhibitionHall.usd'\n",
    "    FRUIT_PROPS = {\n",
    "        'apple': 'omniverse://ove-nucleus.courses.nvidia.com/NVIDIA/Assets/ArchVis/Residential/Food/Fruit/Apple.usd',\n",
    "        'avocado': 'omniverse://ove-nucleus.courses.nvidia.com/NVIDIA/Assets/ArchVis/Residential/Food/Fruit/Avocado01.usd',\n",
    "        'kiwi': 'omniverse://ove-nucleus.courses.nvidia.com/NVIDIA/Assets/ArchVis/Residential/Food/Fruit/Kiwi01.usd',\n",
    "        'lime': 'omniverse://ove-nucleus.courses.nvidia.com/NVIDIA/Assets/ArchVis/Residential/Food/Fruit/Lime01.usd',\n",
    "        'lychee': 'omniverse://ove-nucleus.courses.nvidia.com/NVIDIA/Assets/ArchVis/Residential/Food/Fruit/Lychee01.usd',\n",
    "        'pomegranate': 'omniverse://ove-nucleus.courses.nvidia.com/NVIDIA/Assets/ArchVis/Residential/Food/Fruit/Pomegranate01.usd',\n",
    "        'onion': 'omniverse://ove-nucleus.courses.nvidia.com/NVIDIA/Assets/ArchVis/Residential/Food/Vegetables/RedOnion.usd',\n",
    "        'strawberry': 'omniverse://ove-nucleus.courses.nvidia.com/NVIDIA/Assets/ArchVis/Residential/Food/Berries/strawberry.usd',\n",
    "        'lemon': 'omniverse://ove-nucleus.courses.nvidia.com/NVIDIA/Assets/ArchVis/Residential/Decor/Tchotchkes/Lemon_01.usd',\n",
    "        'orange': 'omniverse://ove-nucleus.courses.nvidia.com/NVIDIA/Assets/ArchVis/Residential/Decor/Tchotchkes/Orange_01.usd'    }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next portion of this script will define our randomization functions. The first of which randomizes the fruits in the crate. Below we will define what key lines are doing:\n",
    "\n",
    " - ```instances = rep.randomizer.instantiate(file_name, size=max_number, mode='scene_instance')```\n",
    "    - Create `scene_instances` from fruits list so we can use the [physics properties](https://docs.omniverse.nvidia.com/prod_extensions/prod_extensions/ext_replicator/physics_example.html#using-the-replicator-apis) supplied by Replicator.\n",
    " - ```rep.modify.pose( ... )```\n",
    "    - Here we define the distribution of locations for the fruits to be placed, all fall within the range of the crate. We add more variation by allowing the scale of the fruit to change. \n",
    " - ```rep.modify.visibility( ... )```\n",
    "    - Finally we are varying the visibility of the fruit so that each image doesn't have all the fruits from the list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    " def random_props(file_name, class_name, max_number=1, one_in_n_chance=3):\n",
    "        instances = rep.randomizer.instantiate(file_name, size=max_number, mode='scene_instance')\n",
    "        with instances:\n",
    "            # First implementation of collisions for Replicator, further work coming to keep objects from overlapping\n",
    "            rep.physics.collider()\n",
    "            rep.modify.semantics([('class', class_name)])\n",
    "            rep.modify.pose(\n",
    "                position=rep.distribution.uniform((-4, 4, -25), (4, 15, 25)),\n",
    "                rotation=rep.distribution.uniform((-180,-180, -180), (180, 180, 180)),\n",
    "                scale = rep.distribution.uniform((0.8), (1.2)),\n",
    "            )\n",
    "            rep.modify.visibility(rep.distribution.choice([True],[False]*(one_in_n_chance)))\n",
    "        return instances.node\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a similar fashion we will randomize the the lighting in each frame. This will add more variation to our dataset and will more closely reflect the different conditions we might see in the real world.\n",
    "\n",
    "We create sphere lights where each available property is altered. The positions, scale, and look of the light is randomized for each image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def sphere_lights(num):\n",
    "    lights = rep.create.light(\n",
    "        light_type=\"Sphere\",\n",
    "        temperature=rep.distribution.normal(3000, 500),\n",
    "        intensity=rep.distribution.normal(30000, 1000),\n",
    "        position=rep.distribution.uniform((-300, -300, -300), (300, 300, 300)),\n",
    "        scale=rep.distribution.uniform(50, 100),\n",
    "        count=num        )\n",
    "    return lights.node\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we register these randomization functions for our Replicator script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "rep.randomizer.register(random_props)\n",
    "rep.randomizer.register(sphere_lights)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To set up our static elements, we use `rep.create.from_usd` for the environment, crate, and surface. These will remain static for every frame. For the surface we are enabling the `physics.collider` so that our crate will fall onto the surface.\n",
    "\n",
    "For the crate we add some additional information. We again add the `physics.collider` and also give the crate a weight. The position of the crate is also statically defined to the center of our surface.\n",
    "\n",
    "At this phase all of our static elements are set in the scene. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "```python\n",
    "env = rep.create.from_usd(ENVS)\n",
    "surface = rep.create.from_usd(SURFACE)\n",
    "with surface:\n",
    "    rep.physics.collider()\n",
    "crate = rep.create.from_usd(CRATE)\n",
    "with crate:\n",
    "    rep.physics.collider()\n",
    "    rep.physics.mass(mass=100)\n",
    "    rep.modify.pose(\n",
    "            position=(0,20,0),\n",
    "            rotation=(0, 0, 90)\n",
    "        )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every Replicator script we write we will want to create a camera that looks at our scene. We then attach the camera to a render product. This combination allows for the viewport by which each frame will be generated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "camera =  rep.create.camera()\n",
    "render_product = rep.create.render_product(camera, resolution=(1024, 1024))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we are looking to start the randomization for each frame. For this use case we are generating 100 data frames. First we loop through the fruit we defined and utilize the randomize function.  We also run the light randomization function. \n",
    "\n",
    "The final step here is to modify the position of our camera. Instead of showing the crate from the same angle for every frame we use the camera position to simulate crate movement. The key here is `look_at` which ensures that even as we move the camera we continue to look at the crate position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "with rep.trigger.on_frame(num_frames=100):\n",
    "    rep.modify.timeline(5, \"frame\")\n",
    "    for n, f in FRUIT_PROPS.items():\n",
    "        random_props(f, n)\n",
    "    rep.randomizer.sphere_lights(5)\n",
    "    with camera:\n",
    "        rep.modify.pose(position=rep.distribution.uniform((-20, 90, -17), (10, 140, -15)), look_at=(0,20,0))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, for this sample we utilize the built in [basic writer](https://docs.omniverse.nvidia.com/extensions/latest/ext_replicator/writer_examples.html#basic-writer). We attach this writer to the render product to produce the dataset output. For our training we want to have the original images as well as the bounding box coordinates and label annotations. \n",
    "\n",
    "We utilize the date information we imported at the top of the script to save our data to a specific location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "writer = rep.WriterRegistry.get(\"BasicWriter\")\n",
    "now=now.strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "output_dir = \"/dli/task/data/fruit_data_\"+now\n",
    "writer.initialize( output_dir=output_dir, rgb=True, bounding_box_2d_tight=True)\n",
    "writer.attach([render_product])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Behind the scenes, Replicator is creating an [OmniGraph](https://docs.omniverse.nvidia.com/prod_extensions/prod_extensions/ext_omnigraph.html#omnigraph-short) which Omniverse will execute. This line does the execution and without it we would not get any ouput."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "rep.orchestrator.run()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 0.4 Running the Replicator Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run our data generation script that we have just stepped through! Copy the command from below (starting at `cd` and ending at `.py`) and paste it into a terminal. You can get a new terminal by clicking the blue `+` and then `Terminal`. Note: your first time running will take Replicator some time to run.  You may see a number of warnings and even errors in the output of terminal window.  When the replicator script is complete, you'll receive"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "cd /home/user/.local/share/ov/pkg/code-2022.3.1 && ./omni.code.sh --no-window --/omni/replicator/script=/opt/project/generate_data_headless.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: your first time running will take Replicator several minutes to complete (estimate 10 minutes).  You may see a number of warnings and even errors in the output of terminal window during the script execution.  When the replicator script is complete, you'll receive a notice that the application is stopping and the terminal prompt will appear:\n",
    "\n",
    "```yaml\n",
    "[C 2023-04-19 20:28:29.590 ServerApp] received signal 15, stopping\n",
    "[I 2023-04-19 20:28:29.591 ServerApp] Shutting down 3 extensions\n",
    "[I 2023-04-19 20:28:29.591 ServerApp] Shutting down 0 terminals\n",
    "user@ip:~/.local/share/ov/pkg/code-2022.3.1$ \n",
    "```\n",
    "\n",
    "Your new output is in the `data` directory.  There should be a new folder, `fruit_data_$DATE` containing the generated data, including some `.png` files you can open and view with a simple double-click."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.4.1 Bonus Replicator API Work\n",
    "\n",
    "If you are looking for some bonus work, navigate to the Replicator script you ran above `/opt/project/generate_data_headless.py` and open in Visual Studio Code. From there you can make your own edits. Some suggestions that won't effect the training are, changing your scene, changing the environment, changing the lighting randomization. Though these changes can be made in the python script, you may find working with the script in the Omniverse Code GUI to be useful. When you are ready to test your changes either copy to the `Script Editor` in Omniverse Code or rerun the command above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<h2 style=\"color:green;\">Congratulations!</h2>\n",
    "\n",
    "In this notebook, you have:\n",
    "- Learned how the Omniverse Code GUI can be used to start generating synthetic data\n",
    "- Explored and run a basic Replicator Python script\n",
    "- Generated a synthetic dataset headlessly through the terminal\n",
    "\n",
    "When you are ready to move on to using your dataset for training, close this window and click the \"Training Lab\" link on the remote desktop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
