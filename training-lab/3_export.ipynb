{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1dace1b",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e669c9e",
   "metadata": {},
   "source": [
    "# 3.0 Export the Model\n",
    "In this notebook, you'll convert your model into a format compatible with deployment.\n",
    "\n",
    "**[3.1 Learning Objectives](#3.1-Learning-Objectives)<br>**\n",
    "**[3.2 Setup for Export](#3.2-Setup-for-Export)<br>**\n",
    "**[3.3 Export Model](#3.3-Export-Model)<br>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f1d531",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.1 Learning Objectives\n",
    "\n",
    "Now we have a trained model that we must to convert before deploying. The [ONNX format](https://onnx.ai/) works well for deploying our model to [NVIDIA's Triton Inference Server](https://developer.nvidia.com/nvidia-triton-inference-server)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4023011-cf41-41a2-9673-00f5a730c070",
   "metadata": {},
   "source": [
    "<center><video controls src=\"https://dli-lms.s3.amazonaws.com/assets/s-ov-10-v1/DLI_part_6.mp4\" width=800 ></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca72a0b-0fa9-496c-8d7f-04af2bae5eaf",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.2 Setup for Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6a0ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14f053d",
   "metadata": {},
   "source": [
    "We first need to point to where out current PyTorch model is saved with the `pytorch_dir` variable. The location is set to our default model, but feel free to change it to the location of your own model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9a5ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_dir = \"/dli/task/data/model.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9277e7c",
   "metadata": {},
   "source": [
    "Define our device to enable the GPU, as we did previously for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a1f045-fa0b-4766-99e7-a8abb3db9fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d96d5f",
   "metadata": {},
   "source": [
    "Let's now load the PyTorch model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d8f556",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(pytorch_dir).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5966f280",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.3 Export Model\n",
    "\n",
    "We will now export our trained model for deployment. ONNX is an open format built to represent machine learning models. Read more about it [here](https://onnx.ai/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b969d5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.rand(1, 3, 1024, 1024).cuda()\n",
    "\n",
    "torch.onnx.export(model,\n",
    "               dummy_input,\n",
    "               \"model.onnx\",\n",
    "               opset_version=11,\n",
    "               input_names=[\"input\"],\n",
    "               output_names=[\"boxes\", \"labels\", \"scores\"]\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774919f1",
   "metadata": {},
   "source": [
    "Now we have a model ready for deployment! We will be moving into our Triton container. if you would like to use your ONNX model, run the cell below. Otherwise you can continue with the pretrained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e149dc-a0c2-49a4-8c22-04d6b25d9a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp model.onnx /dli/task/data/custom_model.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775ef726-0b83-4ffd-85a6-b6eda4d7cbe6",
   "metadata": {},
   "source": [
    "---\n",
    "<h2 style=\"color:green;\">Congratulations!</h2>\n",
    "\n",
    "In this notebook, you have:\n",
    "- Exported your PyTorch model to the ONNX format\n",
    "\n",
    "Once you are ready, move on to the deployment notebooks. Close this window and click the \"Deployment Lab\" link on the desktop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4af74c",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
